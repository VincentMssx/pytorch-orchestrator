apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pytorch-worker
spec:
  serviceName: "pytorch-master-svc"
  replicas: 2 # Number of workers
  selector:
    matchLabels:
      app: pytorch-distributed
      role: worker
  template:
    metadata:
      labels:
        app: pytorch-distributed
        role: worker
    spec:
      imagePullSecrets:
        - name: ghcr-creds
      containers:
        - name: pytorch-worker
          image: ghcr.io/vincent/pytorch-orchestrator:latest # Your Docker image
          env:
            - name: MASTER_ADDR
              value: "pytorch-master-svc"
            - name: MASTER_PORT
              value: "29400"
          command: ["torchrun"]
          args:
            - "--nproc_per_node=1"
            - "--nnodes=3" # 1 master + 2 workers
            - "--rdzv_id=elastic_job_123"
            - "--rdzv_backend=c10d"
            - "--rdzv_endpoint=$(MASTER_ADDR):$(MASTER_PORT)"
            - "--max-restarts=3"
            - "worker.py"
            - "--total_steps=10000"
            - "--batch_size=32"
            - "--dataset_size=5000"
            - "--lr=0.01"
            - "--checkpoint_dir=/mnt/checkpoints"
            - "--checkpoint_interval=1000"
            - "--backend=gloo"
          volumeMounts:
            - name: checkpoint-storage
              mountPath: /mnt/checkpoints
      restartPolicy: OnFailure # Restart pods if they fail
  volumeClaimTemplates:
    - metadata:
        name: checkpoint-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 1Gi # Adjust storage size as needed